# 高性能计算导论 PA4

> 2017011620  计73  李家昊

### 实现方式

本实验需要实现稀疏矩阵与稠密矩阵相乘（SpMM）的 GPU 加速算法，即计算 $C = AB$，其中 $A$ 为 $M\times M$ 的稀疏矩阵，以 CSR 格式存储，$B,C$ 均为 $M \times K$ 的稠密矩阵。

具体实现中，主要参考了 GE-SpMM 算法，对朴素的 SpMM 算法进行了以下两点优化：

1. 一个线程块负责 $C$ 矩阵中某一行的连续元素，首先所有线程将 $A$ 矩阵的对应行从全局内存加载到共享内存，然后每个线程分别遍历共享内存执行计算任务，有利于降低全局访存开销。
2. 每个线程负责 $C$ 矩阵中的多个元素，而非单个，有利于复用线程块内的共享内存和寄存器，减少全局内存的重复访问。

### 实验结果

在公开的 13 个测例上进行性能测试，在 $K=32,64,128,256,512$ 时，测试 CuSparse 和 opt 版本的 SpMM 算法的运行时间，计算加速比，所有实验均在 conv3 节点上进行。

首先分析测例的统计特征，如下表所示。

| 测例         | 矩阵行数 $M$ | 非零元个数  nnz | 平均每行非零元个数 |
| ------------ | ------------- | --------------- | ------------------ |
| arxiv        | 169343        | 1166243         | 6.89               |
| collab       | 235868        | 2358104         | 10.00              |
| citation     | 2927963       | 30387995        | 10.38              |
| ddi          | 4267          | 2135822         | 500.54             |
| protein      | 132534        | 79122504        | 597.00             |
| ppa          | 576289        | 42463862        | 73.69              |
| reddit.dgl   | 232965        | 114615891       | 491.99             |
| products     | 2449029       | 123718280       | 50.52              |
| youtube      | 1138499       | 5980886         | 5.25               |
| amazon_cogdl | 1569960       | 264339468       | 168.37             |
| yelp         | 716847        | 13954819        | 19.47              |
| wikikg2      | 2500604       | 16109182        | 6.44               |
| am           | 881680        | 5668682         | 6.43               |

当 $K = 32$ 时，CuSparse 和 opt 版本的 SpMM 算法运行时间及加速比如下表所示。

| 测例         | CuSparse 运行时间（ms） | opt 运行时间（ms） | 加速比    |
| ------------ | ----------------------- | ------------------ | --------- |
| arxiv        | 0.771                   | 1.137              | 0.678     |
| collab       | 1.331                   | 0.625              | **2.128** |
| citation     | 16.449                  | 8.981              | **1.831** |
| ddi          | 0.641                   | 0.276              | **2.324** |
| protein      | 24.609                  | 8.169              | **3.013** |
| ppa          | 18.393                  | 10.198             | **1.804** |
| reddit.dgl   | 48.656                  | 21.461             | **2.267** |
| products     | 55.822                  | 31.903             | **1.750** |
| youtube      | 3.644                   | 3.025              | **1.204** |
| amazon_cogdl | 125.312                 | 53.447             | **2.345** |
| yelp         | 6.574                   | 3.499              | **1.879** |
| wikikg2      | 7.148                   | 4.400              | **1.625** |
| am           | 3.741                   | 12.367             | 0.302     |

当 $K = 64$ 时，CuSparse 和 opt 版本的 SpMM 算法运行时间及加速比如下表所示。

| 测例         | CuSparse 运行时间（ms） | opt 运行时间（ms） | 加速比    |
| ------------ | ----------------------- | ------------------ | --------- |
| arxiv        | 0.957                   | 1.694              | 0.565     |
| collab       | 1.595                   | 1.092              | **1.461** |
| citation     | 22.068                  | 16.843             | **1.310** |
| ddi          | 0.684                   | 0.448              | **1.525** |
| protein      | 30.859                  | 17.142             | **1.800** |
| ppa          | 24.498                  | 20.393             | **1.201** |
| reddit.dgl   | 65.854                  | 46.341             | **1.421** |
| products     | 74.806                  | 61.803             | **1.210** |
| youtube      | 4.462                   | 4.682              | 0.953     |
| amazon_cogdl | 179.655                 | 111.452            | **1.612** |
| yelp         | 8.672                   | 6.816              | **1.272** |
| wikikg2      | 7.179                   | 4.893              | **1.467** |
| am           | 5.146                   | 16.675             | 0.309     |


当 $K = 128$ 时，CuSparse 和 opt 版本的 SpMM 算法运行时间及加速比如下表所示。

| 测例         | CuSparse 运行时间（ms） | opt 运行时间（ms） | 加速比    |
| ------------ | ----------------------- | ------------------ | --------- |
| arxiv        | 1.522                   | 2.304              | 0.660     |
| collab       | 2.598                   | 2.173              | **1.195** |
| citation     | 39.291                  | 33.919             | **1.158** |
| ddi          | 0.843                   | 0.826              | **1.021** |
| protein      | 42.544                  | 34.251             | **1.242** |
| ppa          | 42.457                  | 40.603             | **1.046** |
| reddit.dgl   | 101.820                 | 91.891             | **1.108** |
| products     | 129.171                 | 123.710            | **1.044** |
| youtube      | 7.215                   | 7.901              | 0.913     |
| amazon_cogdl | 258.982                 | 219.136            | **1.182** |
| yelp         | 14.928                  | 13.382             | **1.116** |
| wikikg2      | 8.362                   | 9.833              | 0.850     |
| am           | 6.810                   | 19.342             | 0.352     |


当 $K = 256$ 时，CuSparse 和 opt 版本的 SpMM 算法运行时间及加速比如下表所示。

| 测例         | CuSparse 运行时间（ms） | opt 运行时间（ms） | 加速比    |
| ------------ | ----------------------- | ------------------ | --------- |
| arxiv        | 2.993                   | 3.631              | 0.824     |
| collab       | 5.202                   | 4.320              | **1.204** |
| citation     | 78.821                  | 69.038             | **1.142** |
| ddi          | 1.553                   | 1.555              | 0.999     |
| protein      | 80.821                  | 68.306             | **1.183** |
| ppa          | 84.963                  | 81.059             | **1.048** |
| reddit.dgl   | 202.347                 | 183.712            | **1.101** |
| products     | 258.353                 | 248.145            | **1.041** |
| youtube      | 14.441                  | 14.223             | **1.015** |
| amazon_cogdl | 517.157                 | 436.117            | **1.186** |
| yelp         | 29.981                  | 26.625             | **1.126** |
| wikikg2      | 16.646                  | 19.588             | 0.850     |
| am           | 13.409                  | 24.788             | 0.541     |

当 $K = 512$ 时，CuSparse 和 opt 版本的 SpMM 算法运行时间及加速比如下表所示。

| 测例         | CuSparse 运行时间（ms） | opt 运行时间（ms） | 加速比    |
| ------------ | ----------------------- | ------------------ | --------- |
| arxiv        | 5.968                   | 6.399              | 0.933     |
| collab       | 10.489                  | 8.874              | **1.182** |
| citation     | oom                     | oom                | oom       |
| ddi          | 3.494                   | 3.048              | **1.146** |
| protein      | 167.136                 | 136.952            | **1.220** |
| ppa          | 170.932                 | 162.488            | **1.052** |
| reddit.dgl   | 409.050                 | 366.005            | **1.118** |
| products     | 524.739                 | 547.700            | 0.958     |
| youtube      | 28.995                  | 27.544             | **1.053** |
| amazon_cogdl | 1047.090                | 881.269            | **1.188** |
| yelp         | 60.912                  | 53.893             | **1.130** |
| wikikg2      | 33.294                  | 39.996             | 0.832     |
| am           | 26.978                  | 36.143             | 0.746     |

从上述实验结果可以看出，在大部分测例上，opt 版本相对于 CuSparse 版本的加速比大于 1。结合测例的统计特征可以看出，当 $A$ 矩阵越稠密时，opt 相对 CuSparse 的加速比越高；当 $A$ 矩阵极为稀疏（平均每行非零元低于 8 个）时，opt 版本有可能慢于 CuSparse。

### 参考资料

+ Huang, G., Dai, G., Wang, Y., & Yang, H. (2020, November). Ge-spmm: General-purpose sparse matrix-matrix multiplication on gpus for graph neural networks. In SC20: International Conference for High Performance Computing, Networking, Storage and Analysis (pp. 1-12). IEEE. [[paper]](https://arxiv.org/abs/2007.03179) [[code]](https://github.com/hgyhungry/ge-spmm)
